<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model - Emergency Voice and Scream Detection System</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <!-- Header -->
    <header class="header">
        <nav class="nav">
            <div class="nav-brand">
                <h1>Emergency Sound Detection</h1>
            </div>
            <ul class="nav-menu">
                <li><a href="../index.html" class="nav-link">Home</a></li>
                <li><a href="model.html" class="nav-link active">Model</a></li>
                <li><a href="visual.html" class="nav-link">System</a></li>
                <li><a href="member.html" class="nav-link">Team</a></li>
            </ul>
        </nav>
    </header>

    <!-- Page Header -->
    <section class="page-header">
        <div class="container">
            <h1>Deep Learning Model</h1>
            <p>Architecture and performance of the CNN+Transformer-based scream detection model</p>
        </div>
    </section>

    <!-- Model Architecture Section -->
    <section class="model-architecture">
        <div class="container">
            <h2 class="section-title">Model Architecture</h2>
            <div class="arch-grid">
                <div class="arch-card">
                    <div class="arch-icon">üîç</div>
                    <h3>CNN Layer</h3>
                    <p>Processes audio data to extract local features. Learns frequency patterns using Conv1d and MaxPool1d.</p>
                    <div class="code-snippet">
                        <code>
nn.Conv1d(input_size, 128, kernel_size=3)<br>
nn.MaxPool1d(kernel_size=2)
                        </code>
                    </div>
                </div>
                <div class="arch-card">
                    <div class="arch-icon">üîÑ</div>
                    <h3>Transformer Layer</h3>
                    <p>Converts CNN outputs into a sequence and learns temporal dependencies, effectively capturing complex patterns.</p>
                    <div class="code-snippet">
                        <code>
nn.TransformerEncoderLayer(<br>
&nbsp;&nbsp;d_model=32, nhead=2<br>
)
                        </code>
                    </div>
                </div>
                <div class="arch-card">
                    <div class="arch-icon">üìä</div>
                    <h3>Classification Layer</h3>
                    <p>Performs binary classification to determine whether a scream is present. Uses the Sigmoid activation function.</p>
                    <div class="code-snippet">
                        <code>
nn.Linear(32, num_classes)<br>
torch.sigmoid(output)
                        </code>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Model Comparison Section -->
    <section class="model-comparison">
        <div class="container">
            <h2 class="section-title">Model Performance Comparison</h2>
            <div class="comparison-table">
                <table>
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>Converged Loss</th>
                            <th>Converged Epochs</th>
                            <th>Final Accuracy</th>
                            <th>Notes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr class="winner">
                            <td><strong>CNN+Transformer</strong></td>
                            <td><span class="metric best">0.0002</span></td>
                            <td><span class="metric best">40</span></td>
                            <td><span class="metric best">99.92%</span></td>
                            <td>Fast convergence, high stability</td>
                        </tr>
                        <tr>
                            <td>CNN-LSTM</td>
                            <td><span class="metric">0.2717</span></td>
                            <td><span class="metric">90</span></td>
                            <td><span class="metric">87.02%</span></td>
                            <td>Moderate performance, some variance</td>
                        </tr>
                        <tr>
                            <td>CNN-GRU</td>
                            <td><span class="metric">0.0387</span></td>
                            <td><span class="metric">80</span></td>
                            <td><span class="metric">77.60%</span></td>
                            <td>Slow convergence, unstable training</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </section>

    <!-- Training Process Section -->
    <section class="training-process">
        <div class="container">
            <h2 class="section-title">Training Process</h2>
            <div class="process-grid">
                <div class="process-step">
                    <div class="step-number">1</div>
                    <h3>Data Preprocessing</h3>
                    <p>Classifies scream and normal audio using a Kaggle dataset and converts signals to frequency-domain features via Fourier transform.</p>
                    <div class="tech-list">
                        <span class="tech-tag">Fourier Transform</span>
                        <span class="tech-tag">STFT</span>
                        <span class="tech-tag">Librosa</span>
                    </div>
                </div>
                <div class="process-step">
                    <div class="step-number">2</div>
                    <h3>Model Training</h3>
                    <p>Trains with batch size 32 and learning rate 0.001 using the Adam optimizer.</p>
                    <div class="tech-list">
                        <span class="tech-tag">Adam Optimizer</span>
                        <span class="tech-tag">Cross Entropy Loss</span>
                        <span class="tech-tag">PyTorch</span>
                    </div>
                </div>
                <div class="process-step">
                    <div class="step-number">3</div>
                    <h3>Performance Evaluation</h3>
                    <p>Evaluates the model comprehensively using metrics such as accuracy, loss, and F1-score.</p>
                    <div class="tech-list">
                        <span class="tech-tag">Accuracy</span>
                        <span class="tech-tag">Precision</span>
                        <span class="tech-tag">Recall</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Key Features Section -->
    <section class="key-features">
        <div class="container">
            <h2 class="section-title">Key Features</h2>
            <div class="features-grid">
                <div class="feature-item">
                    <div class="feature-icon">‚ö°</div>
                    <h3>Fast Convergence</h3>
                    <p>The CNN+Transformer model reaches optimal performance in just 40 epochs, over 2√ó faster than other baselines.</p>
                </div>
                <div class="feature-item">
                    <div class="feature-icon">üéØ</div>
                    <h3>High Accuracy</h3>
                    <p>Achieves 99.92% accuracy, reliably distinguishing screams from normal audio for real-world emergencies.</p>
                </div>
                <div class="feature-item">
                    <div class="feature-icon">üìà</div>
                    <h3>Stable Training</h3>
                    <p>Loss decreases steadily during training, reaching a very low final loss of 0.0002.</p>
                </div>
                <div class="feature-item">
                    <div class="feature-icon">üîÑ</div>
                    <h3>Hybrid Architecture</h3>
                    <p>Combines CNN‚Äôs local pattern recognition with Transformer‚Äôs global dependency modeling for optimal performance.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Data Processing Section -->
    <section class="data-processing">
        <div class="container">
            <h2 class="section-title">Data Processing Pipeline</h2>
            <div class="process-flow">
                <div class="flow-step">
                    <div class="flow-icon">üéµ</div>
                    <h4>Raw Audio</h4>
                    <p>WAV, MP3 formats</p>
                </div>
                <div class="flow-arrow">‚Üí</div>
                <div class="flow-step">
                    <div class="flow-icon">üîÑ</div>
                    <h4>Preprocessing</h4>
                    <p>16 kHz resampling and normalization</p>
                </div>
                <div class="flow-arrow">‚Üí</div>
                <div class="flow-step">
                    <div class="flow-icon">üìä</div>
                    <h4>STFT</h4>
                    <p>Time‚Äìfrequency domain transform</p>
                </div>
                <div class="flow-arrow">‚Üí</div>
                <div class="flow-step">
                    <div class="flow-icon">ü§ñ</div>
                    <h4>Model Input</h4>
                    <p>Converted to tensors for training</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Technical Specifications -->
    <section class="tech-specs">
        <div class="container">
            <h2 class="section-title">Technical Specifications</h2>
            <div class="specs-grid">
                <div class="spec-category">
                    <h3>Input Data</h3>
                    <ul>
                        <li>Sampling Rate: 16 kHz</li>
                        <li>Input Size: 257</li>
                        <li>Batch Size: 32</li>
                        <li>Frame Length: 10 seconds</li>
                    </ul>
                </div>
                <div class="spec-category">
                    <h3>Model Structure</h3>
                    <ul>
                        <li>CNN: Conv1d + MaxPool1d</li>
                        <li>Transformer: 2-head attention</li>
                        <li>Output: Binary classification (scream/normal)</li>
                        <li>Activations: ReLU, Sigmoid</li>
                    </ul>
                </div>
                <div class="spec-category">
                    <h3>Training Setup</h3>
                    <ul>
                        <li>Optimizer: Adam</li>
                        <li>Learning Rate: 0.001</li>
                        <li>Loss Function: CrossEntropyLoss</li>
                        <li>Max Epochs: 100</li>
                    </ul>
                </div>
                <div class="spec-category">
                    <h3>Performance Metrics</h3>
                    <ul>
                        <li>Accuracy: 99.92%</li>
                        <li>Loss: 0.0002</li>
                        <li>Converged Epochs: 40</li>
                        <li>Inference Time: Real-time</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2024 Signal and Systems Project - Fourier Frontier Team</p>
            <p>Yonsei University</p>
        </div>
    </footer>

    <script src="../js/main.js"></script>
</body>
</html>

<style>
/* Additional styles for model page */
.page-header {
    margin-top: 80px;
    padding: 4rem 0 2rem;
    background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
    color: white;
    text-align: center;
}

.page-header h1 {
    font-size: 3rem;
    margin-bottom: 1rem;
}

.page-header p {
    font-size: 1.2rem;
    opacity: 0.9;
}

/* Model Architecture */
.model-architecture {
    padding: 5rem 0;
    background: white;
}

.arch-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 2rem;
}

.arch-card {
    background: var(--bg-light);
    padding: 2rem;
    border-radius: 12px;
    box-shadow: var(--shadow);
    text-align: center;
    transition: transform 0.3s ease;
}

.arch-card:hover {
    transform: translateY(-5px);
}

.arch-icon {
    font-size: 3rem;
    margin-bottom: 1rem;
}

.code-snippet {
    background: var(--bg-dark);
    color: #10b981;
    padding: 1rem;
    border-radius: 8px;
    margin-top: 1rem;
    font-family: 'Courier New', monospace;
    font-size: 0.9rem;
    text-align: left;
}

/* Model Comparison */
.model-comparison {
    padding: 5rem 0;
    background: var(--bg-light);
}

.comparison-table {
    overflow-x: auto;
    background: white;
    border-radius: 12px;
    box-shadow: var(--shadow);
}

.comparison-table table {
    width: 100%;
    border-collapse: collapse;
}

.comparison-table th,
.comparison-table td {
    padding: 1rem;
    text-align: left;
    border-bottom: 1px solid var(--border-color);
}

.comparison-table th {
    background: var(--gradient);
    color: white;
    font-weight: bold;
}

.comparison-table .winner {
    background: rgba(34, 197, 94, 0.1);
}

.metric {
    padding: 0.3rem 0.8rem;
    border-radius: 20px;
    background: var(--bg-light);
    font-weight: bold;
}

.metric.best {
    background: var(--gradient);
    color: white;
}

/* Training Process */
.training-process {
    padding: 5rem 0;
    background: white;
}

.process-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 2rem;
}

.process-step {
    position: relative;
    background: var(--bg-light);
    padding: 2rem;
    border-radius: 12px;
    box-shadow: var(--shadow);
}

.step-number {
    position: absolute;
    top: -15px;
    left: 2rem;
    width: 40px;
    height: 40px;
    background: var(--gradient);
    color: white;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: bold;
    font-size: 1.2rem;
}

.tech-list {
    margin-top: 1rem;
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
}

.tech-tag {
    background: var(--primary-color);
    color: white;
    padding: 0.3rem 0.8rem;
    border-radius: 15px;
    font-size: 0.8rem;
    font-weight: 500;
}

/* Key Features */
.key-features {
    padding: 5rem 0;
    background: var(--bg-light);
}

.features-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 2rem;
}

.feature-item {
    background: white;
    padding: 2rem;
    border-radius: 12px;
    box-shadow: var(--shadow);
    text-align: center;
}

.feature-icon {
    font-size: 3rem;
    margin-bottom: 1rem;
}

/* Data Processing */
.data-processing {
    padding: 5rem 0;
    background: white;
}

.process-flow {
    display: flex;
    align-items: center;
    justify-content: center;
    flex-wrap: wrap;
    gap: 1rem;
}

.flow-step {
    background: var(--bg-light);
    padding: 2rem;
    border-radius: 12px;
    text-align: center;
    min-width: 180px;
    box-shadow: var(--shadow);
}

.flow-icon {
    font-size: 2.5rem;
    margin-bottom: 1rem;
}

.flow-arrow {
    font-size: 2rem;
    color: var(--primary-color);
    font-weight: bold;
}

/* Technical Specifications */
.tech-specs {
    padding: 5rem 0;
    background: var(--bg-light);
}

.specs-grid {
    display: grid,
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 2rem;
}

.spec-category {
    background: white;
    padding: 2rem;
    border-radius: 12px;
    box-shadow: var(--shadow);
}

.spec-category h3 {
    color: var(--primary-color);
    margin-bottom: 1rem;
    font-size: 1.3rem;
}

.spec-category ul {
    list-style: none;
}

.spec-category li {
    padding: 0.5rem 0;
    border-bottom: 1px solid var(--border-color);
    position: relative;
    padding-left: 1.5rem;
}

.spec-category li::before {
    content: '‚Ä¢';
    position: absolute;
    left: 0;
    color: var(--secondary-color);
    font-weight: bold;
}

@media (max-width: 768px) {
    .process-flow {
        flex-direction: column;
    }
    
    .flow-arrow {
        transform: rotate(90deg);
    }
    
    .comparison-table {
        font-size: 0.9rem;
    }
}
</style>
